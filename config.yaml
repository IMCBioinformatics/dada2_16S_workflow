# This file should contain everything to configure the workflow on a global scale.
# In case of sample based data, it should be complemented by a samples.tsv file that contains
# one row per sample. It can be parsed easily via pandas.

**************
*** inputs ***
**************

# List of files
sampletable: "example_files/samples.tsv"


##Path to where snakemake main directories are. So we can read files from to generate the html report
path: "/home/username/dada2_snakemake_workflow/"


**************
***** QC *****
**************

#fastqc and multiqc only
qc_only: FALSE


#For QC reports, we randomly choose samples to check their reads length distribution, here we exclude controls and undetermined samples
#Example "Water|DNA|Undetermined

sample_removal: "Undetermined"


## Cutadapt
## IMPORTANT ****** If you want to remove primers uncomment line 51  in utils/rules/qc_cutadapt.smk******

# Example: Illumina V3V4 protocol primers
#fwd_primer: "TCGTCGGCAGCGTCAGATGTGTATAAGAGACAGCCTACGGGNGGCWGCAG"
#rev_primer: "GTCTCGTGGGCTCGGAGATGTGTATAAGAGACAGGACTACHVGGGTATCTAATCC"
#fwd_primer_rc: "CTGCWGCCNCCCGTAGGCTGTCTCTTATACACATCTGACGCTGCCGACGA"  
#rev_primer_rc: "GGATTAGATACCCBDGTAGTCCTGTCTCTTATACACATCTCCGAGCCCACGAGAC"

primers:
# Illumina V4 protocol primers
fwd_primer: ""
rev_primer: ""
fwd_primer_rc: ""
rev_primer_rc: ""

#Reads format

R1: "_R1_001"
R2: "_R2_001"


***************
**** DADA2 ****
***************

##Parameters 

#Default is FALSE. If TRUE, multithreading is enabled and the number of available threads is automatically determined.
#If an integer is provided, the number of threads to use is set
threads: 20

#Truncation length (Make sure your reads still overlap after truncation in order to merge them later!)
#truncLen:
#  - 260
#  - 220

#Maximum error rate (maximum number of “expected errors” allowed in a read)
maxEE:
  - 2
  - 2

#Truncate reads at the first instance of a quality score less than or equal to truncQ.
truncQ: 2


#Default 1e8. The minimum number of total bases to use for error rate learning.
learn_nbases: 100e6


#If "consensus": The samples in a sequence table are independently checked for bimeras, and a consensus decision on each sequence variant is made.
chimera_method: "consensus"


#Filtering merged reads that are shorter or longer than the most common length by 7  value of difference
max_length_variation: 7


#Initialize random number generator for reproducibility of taxonomy assignment
seed: 100 


## Taxonomy using idtaxa classifer 
idtaxa_dbs:
 RDP: "/home/username/dada2_snakemake_workflow/utils/databases/RDP_v18-mod_July2020.RData"
 Silva: "/home/username/dada2_snakemake_workflow/utils/databases/SILVA_SSU_r138_2019.RData"
 GTDB: "/home/username/dada2_snakemake_workflow/utils/databases/GTDB_r207-mod_April2022.RData"

idtaxa_species:
 RDP: "/home/username/dada2_snakemake_workflow/utils/databases/rdp_species_assignment_18.fa.gz"
 Silva: "/home/username/dada2_snakemake_workflow/utils/databases/silva_species_assignment_v138.1.fa.gz"
 GTDB: "/home/username/dada2_snakemake_workflow/utils/databases/GTDB_bac120_arc53_ssu_r207_Species.fa.gz"


## Taxonomy using RDP classifier
RDP_dbs:
 RDP: "/home/username/dada2_snakemake_workflow/utils/databases/rdp_train_set_18.fa.gz"
 Silva: "/home/username/dada2_snakemake_workflow/utils/databases/silva_nr99_v138.1_train_set.fa.gz"
 GTDB: "/home/username/dada2_snakemake_workflow/utils/databases/GTDB_bac120_arc53_ssu_r207_Genus.fa.gz"

RDP_species:
 RDP: "/home/username/dada2_snakemake_workflow/utils/databases/rdp_species_assignment_18.fa.gz"
 Silva: "/home/username/dada2_snakemake_workflow/utils/databases/silva_species_assignment_v138.1.fa.gz"
 GTDB: "/home/username/dada2_snakemake_workflow/utils/databases/GTDB_bac120_arc53_ssu_r207_Species.fa.gz"  
